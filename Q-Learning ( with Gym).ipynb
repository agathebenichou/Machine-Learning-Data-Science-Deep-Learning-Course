{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Reinforcement Learning\n",
    "\n",
    "The \"taxi problem\": want to build a self-driving taxi that can pick up passengers at one of a set of fixed locations, drop them off at another location, and get there in the quickest amount of time while avoiding obstacles.\n",
    "\n",
    "The AI Gym lets us create this environment quickly: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "\n",
    "# consistent random seed\n",
    "random.seed(1234)\n",
    "\n",
    "# make environments\n",
    "streets = gym.make(\"Taxi-v3\").env #New versions keep getting released; if -v3 doesn't work, try -v2 or -v4\n",
    "\n",
    "# visualize environment\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "What is seeb:\n",
    "\n",
    "-  R, G, B, and Y are pickup or dropoff locations.\n",
    "-  The BLUE letter indicates where we need to pick someone up from.\n",
    "-  The MAGENTA letter indicates where that passenger wants to go to.\n",
    "-  The solid lines represent walls that the taxi cannot cross.\n",
    "-  The filled rectangle represents the taxi itself - it's yellow when empty, and green when carrying a passenger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The \"streets\" is a 5x5 grid. The state of this world at any time can be defined by:\n",
    "\n",
    "-  Where the taxi is (one of 5x5 = 25 locations)\n",
    "-  What the current destination is (4 possibilities)\n",
    "-  Where the passenger is (5 possibilities: at one of the destinations, or inside the taxi)\n",
    "\n",
    "So there are a total of 25 x 4 x 5 = 500 possible states that describe the world.\n",
    "\n",
    "For each state, there are six possible actions:\n",
    "\n",
    "-  Move South, East, North, or West\n",
    "-  Pickup a passenger\n",
    "-  Drop off a passenger\n",
    "\n",
    "Q-Learning will take place using the following rewards and penalties at each state:\n",
    "\n",
    "-  A successfull drop-off yields +20 points\n",
    "-  Every time step taken while driving a passenger yields a -1 point penalty\n",
    "-  Picking up or dropping off at an illegal location yields a -10 point penalty\n",
    "\n",
    "Moving across a wall just isn't allowed at all.\n",
    "\n",
    "Define an initial state, with the taxi at location (2, 3), the passenger at pickup location 2, and the destination at location 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define initial state for taxi to be (2,3) and passenger to be (2,0)\n",
    "initial_state = streets.encode(2, 3, 2, 0)\n",
    "\n",
    "# initialize streets with initial state\n",
    "streets.s = initial_state\n",
    "\n",
    "# display\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Examine the reward table for this initial state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 9,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display reward table\n",
    "streets.P[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "How to interpret this - each row corresponds to a potential action at this state: move South, North, East, or West, pickup, or dropoff. The four values in each row are the probability assigned to that action, the next state that results from that action, the reward for that action, and whether that action indicates a successful dropoff took place. \n",
    "\n",
    "So for example, moving North from this state would put us into state number 368, incur a penalty of -1 for taking up time, and does not result in a successful dropoff.\n",
    "\n",
    "Q-learning! First, rain our model. At a high level, train over 10,000 simulated taxi runs. For each run, step through time, with a 10% chance at each step of making a random, exploratory step instead of using the learned Q values to guide our actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define a numpy array containing every possible state/action in virtiaul space\n",
    "# initialize those to 0\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n])\n",
    "\n",
    "learning_rate = 0.1 # how quick to learn\n",
    "discount_factor = 0.6\n",
    "exploration = 0.1\n",
    "epochs = 10000 \n",
    "\n",
    "# for all epochs\n",
    "for taxi_run in range(epochs):\n",
    "    \n",
    "    # reset streets\n",
    "    state = streets.reset()\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        \n",
    "        # draw random number\n",
    "        random_value = random.uniform(0, 1)\n",
    "        \n",
    "        # if random number less than exploration rate\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() # Explore a random action\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) # Use the action with the highest q-value\n",
    "            \n",
    "        # aply action and get next step,reward, if done\n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        \n",
    "        # get prev q\n",
    "        prev_q = q_table[state, action]\n",
    "        \n",
    "        # get next max q\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        \n",
    "        # q learning equation\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q)\n",
    "        \n",
    "        # store new q to table\n",
    "        q_table[state, action] = new_q\n",
    "        \n",
    "        # go to next state\n",
    "        state = next_state\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "There is now a table of Q-values that can be quickly used to determine the optimal next step for any given state!\n",
    "\n",
    "Check the table for our initial state above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.40220023, -2.40992942, -2.4024936 , -2.3639511 , -6.29460508,\n",
       "       -8.41978874])"
      ]
     },
     "execution_count": 11,
     "metadata": {
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for initial state where we started state\n",
    "q_table[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The lowest q-value here corresponds to the action \"go West\", which makes sense - that's the most direct route toward our destination from that point. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 6 Step 2\n",
      "+---------+\n",
      "|R: | : :\u001b[34;1mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : :\u001b[43m \u001b[0m: : |\n",
      "| | : | : |\n",
      "|Y| : |\u001b[35mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "# stimulate 10 different trips\n",
    "for tripnum in range(1, 11):\n",
    "    \n",
    "    # reset the state\n",
    "    state = streets.reset()\n",
    "   \n",
    "    done = False\n",
    "    trip_length = 0\n",
    "    \n",
    "    while not done and trip_length < 25:\n",
    "        \n",
    "        # get max action\n",
    "        action = np.argmax(q_table[state])\n",
    "        \n",
    "        # calculate action\n",
    "        next_state, reward, done, info = streets.step(action)\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render(mode='ansi'))\n",
    "        sleep(.5)\n",
    "        state = next_state\n",
    "        trip_length += 1\n",
    "        \n",
    "    sleep(2)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (system-wide)",
   "language": "python",
   "metadata": {
    "cocalc": {
     "description": "Python 3 programming language",
     "priority": 100,
     "url": "https://www.python.org/"
    }
   },
   "name": "python3",
   "resource_dir": "/ext/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}